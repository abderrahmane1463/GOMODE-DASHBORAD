# -*- coding: utf-8 -*-
"""fin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yiL_J7UaOcWX-AvcJpT__iEFqQ-10i1x
"""

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import requests
import json
import time
import random

# --- PAGE CONFIG ---
st.set_page_config(page_title="GoMode Dashboard", layout="wide", page_icon="üöö")

# --- STYLE ---
st.markdown("""
    <style>
    body {
        background-color: #0b0c0c;
        color: #00ff88;
    }
    .css-1d391kg, .css-1avcm0n, .st-bx, .st-c7, .st-ci, .st-ch {
        background-color: #0f1117 !important;
        color: #00ff88 !important;
        border-color: #00ff88 !important;
    }
    .stDataFrame tbody tr:hover {
        background-color: #003322 !important;
    }
    </style>
""", unsafe_allow_html=True)

# --- API CREDENTIALS ---
API_ID = "73212330563628851992"
API_TOKEN = "U7xvZEdBGOgzR6LOFKtkEe4lywTXCDtlP45ZonSauAH7nLWQmDm2Iqvy9UAVup0j"
API_BASE_URL = "https://api.speedmail-dz.app/v1/"

# --- ENHANCED API CALL WITH RATE LIMITING ---
def make_api_request(url, headers, params, max_retries=5, base_delay=2):
    """Make API request with exponential backoff retry logic"""
    for attempt in range(max_retries):
        try:
            # Add random jitter to avoid thundering herd
            if attempt > 0:
                jitter = random.uniform(0.5, 1.5)
                delay = (base_delay ** attempt) * jitter
                st.info(f"Rate limited. Waiting {delay:.1f}s before retry {attempt + 1}/{max_retries}...")
                time.sleep(delay)

            response = requests.get(url, headers=headers, params=params, timeout=30)

            if response.status_code == 429:
                # Rate limited, will retry
                continue
            elif response.status_code == 200:
                return response
            else:
                response.raise_for_status()

        except requests.exceptions.Timeout:
            st.warning(f"Request timeout on attempt {attempt + 1}")
            continue
        except requests.exceptions.RequestException as e:
            if attempt == max_retries - 1:
                raise e
            continue

    # If we get here, all retries failed
    raise requests.exceptions.RequestException("Max retries exceeded")

# --- LOAD DATA FROM API WITH RATE LIMITING ---
@st.cache_data(ttl=300)  # Cache for 5 minutes to reduce API calls
def load_data():
    url = f"{API_BASE_URL}parcels/"
    headers = {
        'X-API-ID': API_ID,
        'X-API-TOKEN': API_TOKEN
    }

    all_data = []
    page = 1
    consecutive_errors = 0
    max_pages = 100  # Safety limit to avoid infinite loops

    # Progress bar for user feedback
    progress_bar = st.progress(0)
    status_text = st.empty()

    while page <= max_pages:
        try:
            status_text.text(f"Loading data... Page {page}")
            progress_bar.progress(min(page / max_pages, 0.99))

            params = {'page': page}
            response = make_api_request(url, headers, params)
            response_json = response.json()

            if 'data' in response_json and isinstance(response_json['data'], list):
                page_data = response_json['data']
                all_data.extend(page_data)

                # If page is empty, we've reached the end
                if not page_data:
                    st.success(f"‚úÖ Data loading complete! Found {len(all_data)} records across {page-1} pages.")
                    break

                # Reset consecutive errors counter
                consecutive_errors = 0
            else:
                st.warning(f"Unexpected response format on page {page}")
                consecutive_errors += 1

            # Check if there are more pages
            if not response_json.get('has_more', False):
                st.success(f"‚úÖ Data loading complete! Found {len(all_data)} records across {page} pages.")
                break

            page += 1

            # Add small delay between requests to be respectful to the API
            time.sleep(0.5)

        except requests.exceptions.RequestException as e:
            consecutive_errors += 1
            st.error(f"Error on page {page}: {str(e)}")

            if consecutive_errors >= 3:
                st.error("Too many consecutive errors. Stopping data fetch.")
                break

            # Wait longer before trying next page after error
            time.sleep(2)
            page += 1

    # Clear progress indicators
    progress_bar.empty()
    status_text.empty()

    if not all_data:
        st.warning("No data retrieved from the API. Check your credentials and try refreshing.")
        return pd.DataFrame()

    st.info(f"Successfully loaded {len(all_data)} records from the API.")
    df = pd.DataFrame(all_data)

    # --- Data Processing ---
    df['date_creation'] = pd.to_datetime(df.get('date_creation'), errors='coerce')
    df['date_expedition'] = pd.to_datetime(df.get('date_expedition'), errors='coerce')
    df['date_last_status'] = pd.to_datetime(df.get('date_last_status'), errors='coerce')
    df['Montant total de la commande'] = df.get('price', 0)
    df['has_recouvrement'] = df.get('has_recouvrement', 0)
    df['Nom de l\'√©l√©ment'] = df.get('product_list')
    df['declared_value'] = df.get('declared_value')
    df['contact_phone'] = df.get('contact_phone')
    df['firstname'] = df.get('firstname')
    df['familyname'] = df.get('familyname')

    df['delivered'] = df['last_status'].str.lower().str.contains("livr√©", na=False)
    df['returned'] = df['last_status'].str.lower().str.contains("retour", na=False)
    df['delivery_delay_days'] = (df['date_last_status'] - df['date_expedition']).dt.days
    df['processing_time_days'] = (df['date_expedition'] - df['date_creation']).dt.days
    df['revenue'] = df['Montant total de la commande'].fillna(0)
    df['lost_revenue'] = df['revenue'].where(df['returned'], 0)
    df['success_revenue'] = df['revenue'].where(df['delivered'], 0)

    return df

# Add refresh button
if st.button("üîÑ Refresh Data", help="Clear cache and reload data from API"):
    st.cache_data.clear()
    st.rerun()

df = load_data()

# --- MAIN DASHBOARD ---
if df.empty:
    st.warning("No data to display. Try refreshing or check the API connection.")
    st.info("üí° **Troubleshooting tips:**\n- Click 'Refresh Data' to try again\n- The API might be temporarily unavailable\n- Check if your API credentials are still valid")
else:
    # --- SIDEBAR FILTERS ---
    st.sidebar.header("üîé Filters")

    # Date Range (‚úÖ patched to include the full last selected day)
    min_date, max_date = df['date_creation'].min(), df['date_creation'].max()
    date_range = st.sidebar.date_input(
        "Select Date Range",
        value=[min_date, max_date],
        min_value=min_date,
        max_value=max_date
    )

    # Origin Wilaya
    origin_filter = st.sidebar.multiselect(
        "Origin Wilaya",
        options=df['from_wilaya_name'].dropna().unique()
    )

    # Destination Wilaya
    dest_filter = st.sidebar.multiselect(
        "Destination Wilaya",
        options=df['to_wilaya_name'].dropna().unique()
    )

    # Courier / Center
    courier_filter = st.sidebar.multiselect(
        "Courier / Center",
        options=df['stopdesk_name'].dropna().unique() if 'stopdesk_name' in df.columns else []
    )

    # --- APPLY FILTERS ---
    df_filtered = df.copy()

    if len(date_range) == 2:
        start = pd.to_datetime(date_range[0])
        # ‚úÖ Add 1 day - 1 second so the full last day is included
        end = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
        df_filtered = df_filtered[(df_filtered['date_creation'] >= start) & (df_filtered['date_creation'] <= end)]

    if origin_filter:
        df_filtered = df_filtered[df_filtered['from_wilaya_name'].isin(origin_filter)]

    if dest_filter:
        df_filtered = df_filtered[df_filtered['to_wilaya_name'].isin(dest_filter)]

    if courier_filter and 'stopdesk_name' in df_filtered.columns:
        df_filtered = df_filtered[df_filtered['stopdesk_name'].isin(courier_filter)]

    # --- DASHBOARD TITLE ---
    st.title("üöõ GoMode COD Dashboard")

    # --- KPIs ---
    st.header("üìà Global KPIs")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total Orders", f"{len(df_filtered):,}")
    col2.metric("Success Rate", f"{df_filtered['delivered'].mean():.1%}")
    col3.metric("Return Rate", f"{df_filtered['returned'].mean():.1%}")
    col4.metric("Avg Delivery Delay", f"{df_filtered['delivery_delay_days'].mean():.1f} days")

    colA, colB = st.columns(2)
    colA.metric("Avg Processing Time", f"{df_filtered['processing_time_days'].mean():.1f} days")
    colB.metric("Avg Shipping Time", f"{df_filtered['delivery_delay_days'].mean():.1f} days")

    # --- Time Distribution ---
    st.subheader("‚è±Ô∏è Time Intervals Distribution")
    time_cols = [
        ("Processing Time (Creation ‚Üí Expedition)", 'processing_time_days', df_filtered['processing_time_days'].dropna()),
        ("Shipping Time (Expedition ‚Üí Last Status)", 'delivery_delay_days', df_filtered['delivery_delay_days'].dropna()),
    ]

    seen = set()
    for label, col, data in time_cols:
        if col not in seen and col in df_filtered.columns and not data.empty:
            st.plotly_chart(px.histogram(df_filtered, x=col, nbins=30, title=label,
                                         color_discrete_sequence=["#00ff88"]),
                            use_container_width=True, key=f"hist_{col}")
            seen.add(col)

    # --- Bottlenecks ---
    st.subheader("üö¶ Bottlenecks & Delays")
    if 'delivery_delay_days' in df_filtered.columns:
        slow_orders = df_filtered.sort_values('delivery_delay_days', ascending=False).head(10)
        if not slow_orders.empty:
            st.dataframe(slow_orders[['order_id', 'from_wilaya_name', 'to_wilaya_name',
                                      'processing_time_days', 'delivery_delay_days',
                                      'last_status', 'date_creation', 'date_expedition',
                                      'date_last_status', 'price']])
        else:
            st.info("No slow orders found in this filter range.")

    # --- Insights ---
    st.subheader("üí° Insights & Recommendations")
    insights = []
    if df_filtered['processing_time_days'].mean() > 1:
        insights.append("Order processing is slow. Consider optimizing warehouse or admin processes.")
    if df_filtered['delivery_delay_days'].mean() > 2:
        insights.append("Shipping times are high. Investigate courier or route efficiency.")
    if not insights:
        insights.append("No major bottlenecks detected. Keep monitoring for improvements!")
    for i, insight in enumerate(insights, 1):
        st.markdown(f"**{i}. {insight}**")

    # --- Revenue ---
    st.subheader("üí∞ COD Revenue Analysis")
    col5, col6, col7 = st.columns(3)
    col5.metric("Total COD Revenue", f"{df_filtered['success_revenue'].sum():,.0f} DA")
    col6.metric("Lost Revenue (Returned)", f"{df_filtered['lost_revenue'].sum():,.0f} DA")
    col7.metric("Recouvrement Rate", f"{df_filtered['has_recouvrement'].mean():.1%}")

    # --- Orders & Revenue by Wilaya ---
    st.subheader("üìç Orders & Revenue by Wilaya")
    if not df_filtered.empty:
        wilaya_stats = df_filtered.groupby("to_wilaya_name").agg(
            orders=("order_id", "count"),
            revenue=("success_revenue", "sum"),
            return_rate=("returned", "mean")
        ).reset_index()

        st.plotly_chart(px.bar(wilaya_stats.sort_values("orders", ascending=False),
                               x="to_wilaya_name", y="orders",
                               title="Orders per Wilaya", color_discrete_sequence=["#00ff88"]),
                        use_container_width=True)

        st.plotly_chart(px.bar(wilaya_stats.sort_values("revenue", ascending=False),
                               x="to_wilaya_name", y="revenue",
                               title="Revenue per Wilaya", color_discrete_sequence=["#00ff88"]),
                        use_container_width=True)

    # --- Most Returned Products ---
    st.subheader("üì¶ Most Returned Products")
    if "Nom de l'√©l√©ment" in df_filtered.columns:
        top_returns = df_filtered[df_filtered['returned']].groupby("Nom de l'√©l√©ment").size().sort_values(ascending=False).head(10)
        st.dataframe(top_returns.rename("Returned Orders"))

    # --- Avg Delivery Delay by Hub ---
    st.subheader("‚è≥ Avg Delivery Delay by Hub")
    if 'stopdesk_name' in df_filtered.columns:
        hub_delays = df_filtered.groupby("stopdesk_name").agg(avg_delay=("delivery_delay_days", "mean")).sort_values("avg_delay", ascending=False)
        st.dataframe(hub_delays.style.format({"avg_delay": "{:.1f} days"}))

    # --- Cash Collection by Wilaya ---
    st.subheader("üßæ Cash Collection by Wilaya")
    if 'has_recouvrement' in df_filtered.columns:
        rec_rate = df_filtered.groupby("to_wilaya_name")["has_recouvrement"].mean().sort_values(ascending=False)
        st.dataframe(rec_rate.rename("Recouvrement Rate").map(lambda x: f"{x:.1%}"))

    # --- High Risk Areas ---
    st.subheader("üö® High-Risk Areas")
    if all(col in df_filtered.columns for col in ['to_wilaya_name', 'returned', 'has_recouvrement', 'order_id']):
        risk_df = df_filtered.groupby("to_wilaya_name").agg(
            return_rate=("returned", "mean"),
            rec_rate=("has_recouvrement", "mean"),
            orders=("order_id", "count")
        ).query("orders > 10").sort_values("return_rate", ascending=False)
        st.dataframe(risk_df)

    # --- Orders Over Time ---
    st.subheader("üìÜ Orders Over Time")
    if 'date_creation' in df_filtered.columns:
        orders_time = df_filtered.groupby(df_filtered["date_creation"].dt.date).size()
        fig_time = px.line(x=orders_time.index, y=orders_time.values,
                           labels={"x": "Date", "y": "Orders"},
                           title="Orders Over Time",
                           markers=True, color_discrete_sequence=["#00ff88"])
        st.plotly_chart(fig_time, use_container_width=True, key="orders_time")

    # --- Product Price vs Declared Value ---
    st.subheader("üßê Product Price vs. Declared Value")
    if 'price' in df_filtered.columns and 'declared_value' in df_filtered.columns:
        valid_price = df_filtered[df_filtered['price'].notna() & df_filtered['declared_value'].notna()]
        fig_scatter = px.scatter(valid_price, x="price", y="declared_value",
                                hover_data=['product_list', "tracking"],
                                title="Product Price vs. Declared Value",
                                color_discrete_sequence=["#00ff88"])
        st.plotly_chart(fig_scatter, use_container_width=True, key="price_declared")

    # --- Blacklist ---
    st.subheader("‚õî Blacklist: Top 50 Return-Prone Customers")
    if all(col in df_filtered.columns for col in ['contact_phone', 'firstname', 'familyname']):
        phone_stats = df_filtered.groupby(['contact_phone', 'firstname', 'familyname']).agg(
            total_orders=('order_id', 'count'),
            retour_count=('returned', 'sum')
        ).reset_index()
        phone_stats = phone_stats[phone_stats['retour_count'] > 0]
        phone_stats = phone_stats.sort_values(['retour_count', 'total_orders'], ascending=[False, False])
        top_blacklist = phone_stats.head(50)
        st.dataframe(top_blacklist, use_container_width=True)
        st.info("These persons (name, surname, phone) have the highest number of returns. Consider blocking or reviewing them.")

    st.markdown("---")
    st.markdown("üîç Built for GoMode logistics ‚Äî powered by Streamlit üíöüñ§")